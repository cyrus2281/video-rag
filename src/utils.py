from moviepy.editor import VideoFileClip
from typing import Iterator, TextIO
from io import StringIO
import whisper
import cv2
import webvtt
import os
from os import path as osp
import json
import textwrap

def element_wise_sum(arr1, arr2):
    """
    vector element-wise sum
    """
    if len(arr1) != len(arr2):
        return None
    result = []
    for i in range(len(arr1)):
        result.append(arr1[i] + arr2[i])
    return result


def extract_audio_from_video(video_path, audio_path):
    """
    Extract audio from video
    """
    clip = VideoFileClip(video_path)
    clip.audio.write_audiofile(audio_path)


def transcribe_audio(audio_file):
    """
    Transcribe audio file
    """
    model = whisper.load_model("small")
    options = dict(task="translate", best_of=1, language="en")
    results = model.transcribe(str(audio_file), **options)
    return results


def format_timestamp(
    seconds: float, always_include_hours: bool = False, fractionalSeperator: str = "."
):
    """
    helper function for convert time in second to time format for .vtt or .srt file
    function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    assert seconds >= 0, "non-negative timestamp expected"
    milliseconds = round(seconds * 1000.0)

    hours = milliseconds // 3_600_000
    milliseconds -= hours * 3_600_000

    minutes = milliseconds // 60_000
    milliseconds -= minutes * 60_000

    seconds = milliseconds // 1_000
    milliseconds -= seconds * 1_000

    hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
    return f"{hours_marker}{minutes:02d}:{seconds:02d}{fractionalSeperator}{milliseconds:03d}"


def str2time(strtime):
    """
    a help function that helps to convert a specific time written as a string in format `webvtt` into a time in miliseconds
    function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    # strip character " if exists
    strtime = strtime.strip('"')
    # get hour, minute, second from time string
    hrs, mins, seconds = [float(c) for c in strtime.split(":")]
    # get the corresponding time as total seconds
    total_seconds = hrs * 60**2 + mins * 60 + seconds
    total_miliseconds = total_seconds * 1000
    return total_miliseconds


def _processText(text: str, maxLineWidth=None):
    """
    Process text to fit within a maximum line width.
    Function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    if maxLineWidth is None or maxLineWidth < 0:
        return text

    lines = textwrap.wrap(text, width=maxLineWidth, tabsize=4)
    return "\n".join(lines)


def write_vtt(transcript: Iterator[dict], file: TextIO, maxLineWidth=None):
    """
    helper function to convert transcripts generated by whisper to .vtt file
    function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    print("WEBVTT\n", file=file)
    for segment in transcript:
        text = _processText(segment["text"], maxLineWidth).replace("-->", "->")

        print(
            f"{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}\n"
            f"{text}\n",
            file=file,
            flush=True,
        )


def write_srt(transcript: Iterator[dict], file: TextIO, maxLineWidth=None):
    """
    Write a transcript to a file in SRT format.
    Example usage:
        from pathlib import Path
        from whisper.utils import write_srt
        result = transcribe(model, audio_path, temperature=temperature, **args)
        # save SRT
        audio_basename = Path(audio_path).stem
        with open(Path(output_dir) / (audio_basename + ".srt"), "w", encoding="utf-8") as srt:
            write_srt(result["segments"], file=srt)

    from typing import Iterator, TextIO, List, Dict, Any, Optional, Sequence, Union

    """
    for i, segment in enumerate(transcript, start=1):
        text = _processText(segment["text"].strip(), maxLineWidth).replace("-->", "->")

        # write srt lines
        print(
            f"{i}\n"
            f"{format_timestamp(segment['start'], always_include_hours=True, fractionalSeperator=',')} --> "
            f"{format_timestamp(segment['end'], always_include_hours=True, fractionalSeperator=',')}\n"
            f"{text}\n",
            file=file,
            flush=True,
        )


def getSubs(segments: Iterator[dict], format: str, maxLineWidth: int = -1) -> str:
    """
    Helper function to get subtitles from segments
    Function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    segmentStream = StringIO()

    if format == "vtt":
        write_vtt(segments, file=segmentStream, maxLineWidth=maxLineWidth)
    elif format == "srt":
        write_srt(segments, file=segmentStream, maxLineWidth=maxLineWidth)
    else:
        raise Exception("Unknown format " + format)

    segmentStream.seek(0)
    return segmentStream.read()


def maintain_aspect_ratio_resize(image, width=None, height=None, inter=cv2.INTER_AREA):
    """
    Resize the image while maintaining the aspect ratio.
    Function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    # Grab the image size and initialize dimensions
    dim = None
    (h, w) = image.shape[:2]

    # Return original image if no need to resize
    if width is None and height is None:
        return image

    # We are resizing height if width is none
    if width is None:
        # Calculate the ratio of the height and construct the dimensions
        r = height / float(h)
        dim = (int(w * r), height)
    # We are resizing width if height is none
    else:
        # Calculate the ratio of the width and construct the dimensions
        r = width / float(w)
        dim = (width, int(h * r))

    # Return the resized image
    return cv2.resize(image, dim, interpolation=inter)


def extract_and_save_frames_and_metadata(
    path_to_video,
    path_to_transcript,
    path_to_save_extracted_frames,
    path_to_save_metadatas,
):
    """
    function `extract_and_save_frames_and_metadata``:
    receives as input a video and its transcript
    does extracting and saving frames and their metadatas
    returns the extracted metadatas
    
    function from https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    """
    # metadatas will store the metadata of all extracted frames
    metadatas = []

    # load video using cv2
    video = cv2.VideoCapture(path_to_video)
    # load transcript using webvtt
    trans = webvtt.read(path_to_transcript)

    # iterate transcript file
    # for each video segment specified in the transcript file
    for idx, transcript in enumerate(trans):
        # get the start time and end time in seconds
        start_time_ms = str2time(transcript.start)
        end_time_ms = str2time(transcript.end)
        # get the time in ms exactly
        # in the middle of start time and end time
        mid_time_ms = (end_time_ms + start_time_ms) / 2
        # get the transcript, remove the next-line symbol
        text = transcript.text.replace("\n", " ")
        # get frame at the middle time
        video.set(cv2.CAP_PROP_POS_MSEC, mid_time_ms)
        success, frame = video.read()
        if success:
            # if the frame is extracted successfully, resize it
            image = maintain_aspect_ratio_resize(frame, height=350)
            # save frame as JPEG file
            img_fname = f"frame_{idx}.jpg"
            img_fpath = osp.join(path_to_save_extracted_frames, img_fname)
            cv2.imwrite(img_fpath, image)

            # prepare the metadata
            metadata = {
                "extracted_frame_path": img_fpath,
                "transcript": text,
                "video_segment_id": idx,
                "video_path": path_to_video,
                "mid_time_ms": mid_time_ms,
            }
            metadatas.append(metadata)

        else:
            print(f"ERROR! Cannot extract frame: idx = {idx}")

    # save metadata of all extracted frames
    fn = osp.join(path_to_save_metadatas, "metadatas.json")
    with open(fn, "w") as outfile:
        json.dump(metadatas, outfile)
    return metadatas


def get_video_segment_from_metadata(metadata, duration, output_path):
    """
    Get a video segment from a video file based on the metadata
    """
    video_path = metadata["video_path"]
    mid_time_ms = metadata["mid_time_ms"]

    clip = VideoFileClip(video_path)
    video_length = clip.duration * 1000

    delta_time = duration * 1000 / 2
    start_time_ms = max(mid_time_ms - delta_time, 0)
    end_time_ms = min(mid_time_ms + delta_time, video_length)

    subclip = clip.subclip(start_time_ms / 1000, end_time_ms / 1000)
    subclip.write_videofile(output_path)

    return output_path

def play_video(video_path:str):
    """
    Opens the video in the default video player
    """
    os.system(f"open {video_path}")